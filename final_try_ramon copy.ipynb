{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Teamname: \n","#### Score: 0.87571 Kagglename: Ramón Jäckle\n","\n","#### Namen der Teammitglieder: Marius Urban, Ramón Jäckle, Maen Hanna"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Standardcode aus Beispiel um Daten zu erhalten"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-22T10:36:28.048450Z","iopub.status.busy":"2023-06-22T10:36:28.048040Z","iopub.status.idle":"2023-06-22T10:36:28.057941Z","shell.execute_reply":"2023-06-22T10:36:28.056716Z","shell.execute_reply.started":"2023-06-22T10:36:28.048419Z"},"id":"dWSiczBK8CoZ","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:28.065262Z","iopub.status.busy":"2023-06-22T10:36:28.063452Z","iopub.status.idle":"2023-06-22T10:36:45.460522Z","shell.execute_reply":"2023-06-22T10:36:45.459324Z","shell.execute_reply.started":"2023-06-22T10:36:28.065210Z"},"id":"OqyxUIDU8Coe","outputId":"53645392-5d9d-40d6-d0f8-b848559c70ed","trusted":true},"outputs":[],"source":["!pip install wget"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T14:35:27.348339Z","iopub.status.busy":"2023-06-25T14:35:27.347953Z","iopub.status.idle":"2023-06-25T14:35:27.355861Z","shell.execute_reply":"2023-06-25T14:35:27.354632Z","shell.execute_reply.started":"2023-06-25T14:35:27.348311Z"},"id":"WVfs2foH8Cof","trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import random\n","import zipfile"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:45.472697Z","iopub.status.busy":"2023-06-22T10:36:45.472338Z","iopub.status.idle":"2023-06-22T10:36:49.980694Z","shell.execute_reply":"2023-06-22T10:36:49.979533Z","shell.execute_reply.started":"2023-06-22T10:36:45.472660Z"},"id":"yBVgiZX38Cog","outputId":"5a2203f8-ea2a-4fa8-fa0c-99e86f83eba0","trusted":true},"outputs":[],"source":["!python -m wget https://filr.hs-offenburg.de/filr/public-link/file-download/0dcf8b85882ae199018870bceddf437c/5426/-2254907074900866378/test_data.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:49.984006Z","iopub.status.busy":"2023-06-22T10:36:49.983251Z","iopub.status.idle":"2023-06-22T10:44:04.290872Z","shell.execute_reply":"2023-06-22T10:44:04.289628Z","shell.execute_reply.started":"2023-06-22T10:36:49.983967Z"},"id":"Ze6dIoM58Coh","outputId":"4eb3903b-ac94-449b-ab0e-e2172660631d","trusted":true},"outputs":[],"source":["!python -m wget https://zenodo.org/record/7869954/files/products_leaflets_256.zip?download=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:44:04.295623Z","iopub.status.busy":"2023-06-22T10:44:04.294953Z","iopub.status.idle":"2023-06-22T10:44:23.880495Z","shell.execute_reply":"2023-06-22T10:44:23.879418Z","shell.execute_reply.started":"2023-06-22T10:44:04.295590Z"},"id":"JiZS91qB8Coh","trusted":true},"outputs":[],"source":["path_to_zip_file = 'products_leaflets_256.zip'\n","directory_to_extract_to = '.'\n","with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJQFpEiJ8Coi","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:44:23.882542Z","iopub.status.busy":"2023-06-22T10:44:23.882049Z","iopub.status.idle":"2023-06-22T10:44:24.338457Z","shell.execute_reply":"2023-06-22T10:44:24.337199Z","shell.execute_reply.started":"2023-06-22T10:44:23.882505Z"},"id":"Ufo6N7-F8Coi","trusted":true},"outputs":[],"source":["path_to_zip_file = 'test_data.zip'\n","directory_to_extract_to = '.'\n","with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Eingangsformat\n","\n","Die Modelle erwarten alle ein einheitliches Eingangsformat der Daten. In dem Fall der Bildausschnitte muss das Pixelformat vereinheitlicht werden sowie das Farbformat. Das Eingangs Format kann in verschiedenen Datentypen gespeichert werden. Im ersten Versuch wurde hierfür ein **Numpy-Array** mit RGB-Konvertierung verwendet. Durch die großen Mengen an Daten ist hierbei der Grafikspeicher recht schnell an seine Grenzen gelangt. **Anmerkung vieleicht nicht ganz sachlich genug an die Grenzen gelangt eher durch speicher reichte bei früheren Versuchen nicht aus.** Abhilfe sollen hierbei die im nächsten Abschnitt erläuterten **Datasets** geben.\n","\n","Die optimale Bildgröße wurde empierisch bestimmt im ersten Versuch wurde mit dem standard Format 224x224 begonnen. Anschließend wurde mit größeren Formaten getestet. Das beste Ergebniss wurde mit dem Format 256x256 erzieht. Erhöt man das Format weiter erziehlt man nur geringe Verbesserungen und erhällt eine längere Laufzeit. **Allgemein wirkt der Teil mit der Bildgrößen hier etwas verloren eher zum nächsten Markdown block verschieben**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3vULfpl8Coi","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import tensorflow as tf\n","\n","# Verzeichnis mit den Trainingsdaten\n","train_directory = 'products_leaflets_256/train'\n","val_directory = 'products_leaflets_256/test'\n","\n","# Bildgröße und Anzahl der Klassen\n","# \n","image_size = (256, 256)\n","num_classes = len(os.listdir(train_directory))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dynamische Eingangsdaten\n","Wie bereits beschrieben wird durch ein standard Numpy-Array zuviel Speicher verwendet. Aus diesem Grund wird hier ein **Dataset** von Keras verwendet. Diese haben nicht nur den Vorteil die Bilder dynamisch in den Speicher zu laden **Hier vielleicht kurz erklären was dynamisches laden bedeutet.**, sie vereinfachen auch das Laden aus den Verzeichnissen. Während bei dem Numpy-Array durch die Ordenerstruktur iteriert werden muss um die Bilder korrekt einzulesen und korrekt zu labeln, wird ein **Dataset** durch einen eizigen Funktionsaufruf erstellt. Über diesen Funktionsaufruf wird außerdem die Größe des zu vereinheitlichen Eingangsformates eingestellt. Das Resizing der Bilder in das einheitliche Eingangsformat wird dann direkt beim Laden in das **Datasets** durchgeführt.\n","\n","Weitere Einsellmöglichkeiten wie bilineare Interpolation beim Resizing, durchmischen der Daten um Overfitting zu vermeiden und die **Batch-Size** können ebenfalls eingestellt werden. Der Wert der **Batch-Size** konnte keine Verbesserung erziehlten daher wurde der Standardwert von 32 übernommen."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T14:35:37.951419Z","iopub.status.busy":"2023-06-25T14:35:37.951056Z","iopub.status.idle":"2023-06-25T14:35:41.944401Z","shell.execute_reply":"2023-06-25T14:35:41.943462Z","shell.execute_reply.started":"2023-06-25T14:35:37.951389Z"},"id":"cf0wCgWd9beC","outputId":"b1303038-2c89-4638-ab46-b7c57e8df9b4","trusted":true},"outputs":[],"source":["# Durchlaufe das Trainingsverzeichnis und lade die Bilder\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    train_directory,\n","    labels=\"inferred\",\n","    label_mode=\"int\",\n","    class_names=None,\n","    color_mode=\"rgb\",\n","    batch_size=32,\n","    image_size=image_size,\n","    shuffle=True,\n","    seed=None,\n","    validation_split=None,\n","    subset=None,\n","    interpolation=\"bilinear\",\n","    follow_links=False,\n","    crop_to_aspect_ratio=False,)\n","\n","# Durchlaufe das Validierungsverzeichnis und lade die Bilder\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    val_directory,\n","    labels=\"inferred\",\n","    label_mode=\"int\",\n","    class_names=None,\n","    color_mode=\"rgb\",\n","    batch_size=32,\n","    image_size=image_size,\n","    shuffle=True,\n","    seed=None,\n","    validation_split=None,\n","    subset=None,\n","    interpolation=\"bilinear\",\n","    follow_links=False,\n","    crop_to_aspect_ratio=False,)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import ResNet50, DenseNet121, DenseNet201, DenseNet169\n","import tensorflow.keras.optimizers.legacy as legacy_optimizers\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Netzauswahl\n","\n","Es wurden verschiedene von Keras bereitgestellte Bildklassifizirungsnetze getestet. Darunter sind Netze wie efficientnet, verschiedene Versionen von ResNet, MobileNet, Densenet und ein selbstgebautes AlexNet. Folgende Netze wurden getestet:\n","\n","+ EfficientNetV2B0\n","+ EfficientNetV2B0\n","+ EfficientNetV2B1\n","+ ResNet50\n","+ ResNet101\n","+ MobileNetV2\n","+ selbstgebautes Alexnet\n","+ DenseNet121\n","+ DenseNet169\n","+ DenseNet201\n","\n","Aus dem DenseNet169 resultierte das beste Ergebnis und wurde deshalb gewählt.\n","\n","Dieses Netz hat vortrainierte Layer und Gewichte diese wurden bei den Standard werten belassen. Durch Testen konnte average Pooling als beste Variante bestimmt werden."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#base_model = MobileNetV2(include_top=False, input_shape=(256, 256, 3))\n","#base_model = DenseNet121(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n","base_model = DenseNet169(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n","#base_model = DenseNet201(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n","#base_model = ResNet50(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Augmentation\n","Alle der zuvor genanten Modelle wurden mit und ohne Dataaugmentation getestet. Ziel war durch das erhöhen der Varianz in den Klassen das Ergebnis zu erhöhen.\n","Es wurden folgende Augmentations getestet:\n","1. Zufällige Rotation des Bildes\n","2. Zufälliges Heran-Zoomen\n","3. Zufälliges horizontales Spiegeln\n","4. Zufällige Kontraständerungen\n","5. Zufällige Helligkeistveränderung\n","\n","Im Falle des finalen Netzes haben ausnahmslos alle diese Maasnahmen zu Verschlechterungen des Ergebnises geführt und wurden daher verworfen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Daten Augmentation\n","data_augmentation = tf.keras.Sequential([\n","    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n","    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n","    tf.keras.layers.RandomFlip(mode = 'horizontal'),\n","    tf.keras.layers.RandomContrast(0.4)\n","])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Modelkonstruktion\n","Bei der Konstruktion des Gesamtmodells wurden mehrere Dinge getestet. Zunächst ein wie bereits erwähnten und verworfenen Data-Argumentation-Layer, sowie mehrere Denselayer auf der Ausgangsseite des Modells und ein Denselayer mit der Anzahl der Klassen als Units da das Original DenseNet 1000 Klassen erwartet. Die zusätzlichen Denselayer welche nicht der Klassenanzahl entsprechen wurden aufgrund von Verschlechterung des Ergebnisses wieder verworfen.\n","Außerdem konnten GlobalAveragePooling2D und BatchNormalization keine Verbesserung erziehlen. Hier konnte man erkennen, dass beim Testen von verschiedenen Netzen verschiedene Parameter zu verbesserungen bzw. Verschlecheterungen beitragen können. Bspw. konnte die Dataaugmentation beim ResNet ein besseres Ergebniss erzielen, wobei sie beim DenseNet das Ergebnis verschlechtert. **Anmerkung: Die pro Netz test können auf alle Parameter bezogen werden daher gehört das meiner Meinung nach entweder zur Netzauswahl oder in den Schluss zur Diskussion**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data Augmentation erweitern\n","model = Sequential([\n","    #data_augmentation,\n","    base_model,\n","    #GlobalAveragePooling2D(),\n","    #BatchNormalization(),\n","    #Dense(256, activation=\"relu\"),\n","    #Dense(128, activation='relu'),\n","    #Dense(64, activation=\"relu\"),\n","    Dense(num_classes, activation='softmax')\n","])\n","base_model.layers[0].trainable = False"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Anpassbare Lernrate\n","Die Lernrate ist ein wichtiger Parameter. Im allgemeinen je geringer die Lernrate umso besser das Lernen**Anmerkung: Vieleicht etwas zu allgemein und nicht sicher ob das so überhaupt richtig ist, aber Diskutabel**. Ist die Lernrate von Anfang an sehr gering dauert das Lernen sehr lange. Meist ist aber zu Begin eine geringe Lernrate nicht nötig. Um die Lernrate je Epoche anzupassen wird die Callbackfunktion **ReduceLROnPlateau** verwendet. Diese reduziert die Lernrate wenn die valdation Accuracy sich 3 mal hintereinader nicht verbessert.\n","So kann zu Begin mit einer vergleichsweise hohen Lernrate gestartet werden. Die Startlernrate wurde ebenfalls empirisch bestimmt. Die Startlernrate von 0,001 hat hier keine guten Ergebnisse erziehlt.\n","\n","Das Resultat dieser Vorgehensweise ist sehr positiv und hat das Ergebniss enorm verbessert."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, min_lr=1e-18)\n","optimizer = Adam(learning_rate=1e-4)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Vorzeitiger Stopp\n","Um ein zu langes Lernen und Overfitting zu verhindern, kann das Trainieren durch einen vorzeitigen Stopp abgebrochen werden. \n","\n","Erziehlt das Model in mehreren Epochen keine Verbesserung ist die Gefahr in ein Overfitting zu gelangen sehr groß und ein Abrechen des Lernens ist sinnvoll.\n","\n","Die zu beobachtende Metrik um die Verbesserung abzuschätzen ist die val_accuracy. Diese gilt es zu maximieren somit ist der Modus **max** zu wählen. Durch den Parameter **patience** wird nach 10 Epochen ohne Verbesserung das Lernen abgebrochen. Dieser Parameter wurde nich optimiert da durch **restore_best_weights** die Gewichte der nach der gewählten Metrik das beste Ergebniss liefern."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EarlyStopping_Cb = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 10, restore_best_weights = True, verbose = 1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Modellkompilierung\n","\n","Die Modellkompilierung kann durch die Wahl der zu optimierenden Metriken verbessert werden. \n","In diesem Fall führt das Optimieren des Accuracy und dem Mean-Scuared Error zur verbesserung des Ergebnisses. \n","\n","## Modelltraining\n","\n","Die Anzahl der vorgegebenen Epochen wird hier 50 gesetzt da das Lernen innerhalb dieser durch die Callbackfunktion frühzeiting gestoppt wird."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T19:19:33.143653Z","iopub.status.busy":"2023-06-25T19:19:33.143272Z","iopub.status.idle":"2023-06-25T21:14:35.698567Z","shell.execute_reply":"2023-06-25T21:14:35.697456Z","shell.execute_reply.started":"2023-06-25T19:19:33.143624Z"},"id":"j85BDjzQNijo","outputId":"59898274-d9bf-473b-f8c8-06472aa72d60","trusted":true},"outputs":[],"source":["model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy', 'mse'])\n","\n","# Trainingsparameter anpassen\n","batch_size = 32\n","epochs = 50\n","# Modelltraining mit erweitertem Data Augmentation\n","model.fit(train_ds,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=val_ds,\n","          callbacks=[reduce_lr, EarlyStopping_Cb])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Prediction und Speichern der Ergebnisse\n","Für die Prediction wird die Liste der Validierungsbilder iterativ in des Modell gegeben. Dabei wird erst der Inhalt des Verzeichnisses in eine Liste übertragen. Danach wird über diese Liste iteriert und dem Modell zur Vorherrsage übergeben. Die vorhergesagten Labels werden in der gleichen Reihenfolge wie die Bilder eingelsen wurden in einem Numpy-Array gespeichert. Die Liste der Bildnamen und der vorhergesagten Labels werden in einem Datenframe von Pandas kombiniert und anschießend in einer CSV-Datei exportiert."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T21:14:45.153676Z","iopub.status.busy":"2023-06-25T21:14:45.152988Z","iopub.status.idle":"2023-06-25T21:16:52.044476Z","shell.execute_reply":"2023-06-25T21:16:52.043553Z","shell.execute_reply.started":"2023-06-25T21:14:45.153636Z"},"id":"OGw5vbNXJbCp","outputId":"6a550fed-f3ac-4c4a-edc6-412566b05465","trusted":true},"outputs":[],"source":["# Liste für Bildnamen und Vorhersagen\n","image_names = os.listdir('./test_data')\n","class_names = sorted(os.listdir(train_directory))\n","label_predictions = []\n","img_array = []\n","test_directory = 'test_data'\n","\n","\n","# Durchlaufe das Testverzeichnis und lade die Bilder\n","for image_name in image_names:\n","    url = \"./test_data/\" + image_name\n","    img = tf.keras.utils.load_img(url, target_size=image_size)\n","    img_array = tf.keras.utils.img_to_array(img)\n","    img_array = tf.expand_dims(img_array, 0)\n","    predictions = model.predict(img_array)\n","    score = tf.nn.softmax(predictions[0])\n","    label_predictions.append(class_names[np.argmax(score)])\n","\n","\n","# Erstelle den DataFrame und speichere die Vorhersagen in einer CSV-Datei\n","df = pd.DataFrame(columns=['image_id', 'label'])\n","df['image_id'] = image_names\n","df['label'] = label_predictions\n","df.to_csv('submission.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2f2q0TcFJyxb"},"source":["## Ergebnisanalyse"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cg2aNC1xJDdB"},"source":["### Was kannnoch besser gemacht werden?\n","\n","Kombinieren des Models mit einer Texterkennung, außerdem könnte mehr Aufwand in der Bildvorverarbeitung ebenfalls Auswirkungen auf ein besseres und vieleicht auch ein robusteres Ergebniss erzielen testen beispielsweise den Kontrast bei allen Bildern erhöhen.\n","\n","\n","### Welche Erkenntnisse konnten durch die Arbeit gewonnen werden?\n","Es ergeben sich einige Punkte, welche in dieser Arbeit bemerkbar wurden. \n","\n","* Jeder Modellansatz muss für sich betrachtet werden. Meist können keine Schlüsse von anderen Modellen auf das aktuelle Modell geschlossen werden. (Wie z.B. Dataaugmentation, GlobalAveragePooling2D und BatchNormalization diese haben bei den Netzen ResNet und EffincentNet zu Verbesserungen geführt)\n","* Durch die Menge an Daten wurde man gezwungen mit datasets zu arbeiten **Anmerkung: Hört sich etwas rupig an das man gezwungen wird, Vielleicht eher die beschreiben als Notwendigkeit für effizienteres Laden der Daten aufgrund begranzten GRakaSpeichers**, welche viele Möglichkeiten bieten Verbesserungen sowie Vereinfachungen zu erreichen\n","* Es müssen nicht immer eigene, aufwändige Ansätze zielführend sein. Meist sind gegebene Ansätze, wie die in der Keras-Bibliothek ausreichend für das gegebene Problem oder wie in diesem Fall sogar besser.\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
