{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### Score: 0.87571 Kagglename: M_Urban\n","\n","#### Namen der Teammitglieder: Marius Urban, Ramon Jäckle, Maen Hanna"]},{"cell_type":"markdown","metadata":{},"source":["Standardcode aus Beispiel um Daten zu erhalten"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-22T10:36:28.048450Z","iopub.status.busy":"2023-06-22T10:36:28.048040Z","iopub.status.idle":"2023-06-22T10:36:28.057941Z","shell.execute_reply":"2023-06-22T10:36:28.056716Z","shell.execute_reply.started":"2023-06-22T10:36:28.048419Z"},"id":"dWSiczBK8CoZ","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:28.065262Z","iopub.status.busy":"2023-06-22T10:36:28.063452Z","iopub.status.idle":"2023-06-22T10:36:45.460522Z","shell.execute_reply":"2023-06-22T10:36:45.459324Z","shell.execute_reply.started":"2023-06-22T10:36:28.065210Z"},"id":"OqyxUIDU8Coe","outputId":"53645392-5d9d-40d6-d0f8-b848559c70ed","trusted":true},"outputs":[],"source":["!pip install wget"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T14:35:27.348339Z","iopub.status.busy":"2023-06-25T14:35:27.347953Z","iopub.status.idle":"2023-06-25T14:35:27.355861Z","shell.execute_reply":"2023-06-25T14:35:27.354632Z","shell.execute_reply.started":"2023-06-25T14:35:27.348311Z"},"id":"WVfs2foH8Cof","trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import random\n","import zipfile"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:45.472697Z","iopub.status.busy":"2023-06-22T10:36:45.472338Z","iopub.status.idle":"2023-06-22T10:36:49.980694Z","shell.execute_reply":"2023-06-22T10:36:49.979533Z","shell.execute_reply.started":"2023-06-22T10:36:45.472660Z"},"id":"yBVgiZX38Cog","outputId":"5a2203f8-ea2a-4fa8-fa0c-99e86f83eba0","trusted":true},"outputs":[],"source":["!python -m wget https://filr.hs-offenburg.de/filr/public-link/file-download/0dcf8b85882ae199018870bceddf437c/5426/-2254907074900866378/test_data.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:49.984006Z","iopub.status.busy":"2023-06-22T10:36:49.983251Z","iopub.status.idle":"2023-06-22T10:44:04.290872Z","shell.execute_reply":"2023-06-22T10:44:04.289628Z","shell.execute_reply.started":"2023-06-22T10:36:49.983967Z"},"id":"Ze6dIoM58Coh","outputId":"4eb3903b-ac94-449b-ab0e-e2172660631d","trusted":true},"outputs":[],"source":["!python -m wget https://zenodo.org/record/7869954/files/products_leaflets_256.zip?download=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:44:04.295623Z","iopub.status.busy":"2023-06-22T10:44:04.294953Z","iopub.status.idle":"2023-06-22T10:44:23.880495Z","shell.execute_reply":"2023-06-22T10:44:23.879418Z","shell.execute_reply.started":"2023-06-22T10:44:04.295590Z"},"id":"JiZS91qB8Coh","trusted":true},"outputs":[],"source":["path_to_zip_file = 'products_leaflets_256.zip'\n","directory_to_extract_to = '.'\n","with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJQFpEiJ8Coi","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:44:23.882542Z","iopub.status.busy":"2023-06-22T10:44:23.882049Z","iopub.status.idle":"2023-06-22T10:44:24.338457Z","shell.execute_reply":"2023-06-22T10:44:24.337199Z","shell.execute_reply.started":"2023-06-22T10:44:23.882505Z"},"id":"Ufo6N7-F8Coi","trusted":true},"outputs":[],"source":["path_to_zip_file = 'test_data.zip'\n","directory_to_extract_to = '.'\n","with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bildgröße\n","\n","Für Bilder muss eine konstante Größe gewählt werden, da dies von den Netzwerken erwartet werden, aber die Bilder aus den Prospekten nicht immer gleich sind.\n","\n","Die Bildgröße wurde folgendermaßen bestimmt.\n","\n","1. Es wurde mit 224, 224 angefangen, da dies die Standardgröße bei den vorgefertigten Netzen aus Keras ist.\n","2. Es wurde schrittweise größere Größen getestet.\n","3. Diese zeigten eine leichte Verbesserung aber nach 256,256 kaum noch, während sich die Laufzeit verschlechterte"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3vULfpl8Coi","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import tensorflow as tf\n","\n","# Verzeichnis mit den Trainingsdaten\n","train_directory = 'products_leaflets_256/train'\n","val_directory = 'products_leaflets_256/test'\n","\n","# Bildgröße und Anzahl der Klassen\n","image_size = (256, 256)\n","num_classes = len(os.listdir(train_directory))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Laden der Bilder\n","Als Datenstruktur für die Bilder wurden Keras Datasets gewählt. Diese bieten folgende Vorteile welche genutzt wurden:\n","1. automatisches Resizing der Bilder mit verschiedenen Interpolationsmöglichkeiten:\n","    + Die zuvor erwähnte Bildgröße mit bilinearer Interpolation wurde gewählt.\n","2. automatische bestimmung der Labels anhand der Ordnerstruktur\n","3. Das durchmischen der Daten um negative Effekte wie Overfitting zu vermeiden die auftreten, wenn Klassen immer in Gruppen nacheinander trainiert werden.\n","4. \"Lazy-loading\" in \"batches\" um zu verhindern, das der VRam der Grafikkarte während des Lernens voll wird.\n","    + Die Batchsize wurde beim Standardwert belassen, da die Batchsize keinen Einfluss auf das Lernergebnis hat, sonder nur minimale Einfluss auf die Laufzeit."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T14:35:37.951419Z","iopub.status.busy":"2023-06-25T14:35:37.951056Z","iopub.status.idle":"2023-06-25T14:35:41.944401Z","shell.execute_reply":"2023-06-25T14:35:41.943462Z","shell.execute_reply.started":"2023-06-25T14:35:37.951389Z"},"id":"cf0wCgWd9beC","outputId":"b1303038-2c89-4638-ab46-b7c57e8df9b4","trusted":true},"outputs":[],"source":["# Durchlaufe das Trainingsverzeichnis und lade die Bilder\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    train_directory,\n","    labels=\"inferred\",\n","    label_mode=\"int\",\n","    class_names=None,\n","    color_mode=\"rgb\",\n","    batch_size=32,\n","    image_size=image_size,\n","    shuffle=True,\n","    seed=None,\n","    validation_split=None,\n","    subset=None,\n","    interpolation=\"bilinear\",\n","    follow_links=False,\n","    crop_to_aspect_ratio=False,)\n","\n","# Durchlaufe das Validierungsverzeichnis und lade die Bilder\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    val_directory,\n","    labels=\"inferred\",\n","    label_mode=\"int\",\n","    class_names=None,\n","    color_mode=\"rgb\",\n","    batch_size=32,\n","    image_size=image_size,\n","    shuffle=True,\n","    seed=None,\n","    validation_split=None,\n","    subset=None,\n","    interpolation=\"bilinear\",\n","    follow_links=False,\n","    crop_to_aspect_ratio=False,)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import DenseNet169\n","import tensorflow.keras.optimizers.legacy as legacy_optimizers\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Netzauswahl\n","Es wurden verschiedene von Keras bereitgestellte Bilderkennungsnetze getestet. Folgende wurden getestet:\n","+ EfficientNetV2B0\n","+ EfficientNetV2B1\n","+ ResNet50\n","+ ResNet101\n","+ MobileNetV2\n","+ DenseNet121\n","+ DenseNet169\n","+ DenseNet201\n","\n","Desweiteren wurde ein selbstgebautes Alexnet getestet.\n","\n","DenseNet169 schnitt am besten ab und wurde deshalb gewählt.\n","\n","Das Netz wurde mit vortrainierten \"imagenet\" Gewichten genutzt.\n","Diese wurden fürs Training eingefroren, da selbsttrainieren das Ergebnis nur verschlechterte.\n","Durch Testen wurde average Pooling als beste Variante bestimmt."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_model = DenseNet169(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n","base_model.layers[0].trainable = False"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data-Augmentation\n","Es wurde mit verschiedenen Methoden experimentiert um Bilder mittels Data-Augmentation zu verändern um die Varianz der Bilder in den Klassen zu erhöhen.\n","Es wurden folgende Augmentations getestet:\n","1. Zufällige Rotation des Bildes\n","2. Zufälliges Heran-Zoomen\n","3. Zufälliges horizontales spiegeln\n","4. Zufällige Kontraständerungen\n","\n","Ausnahmslos alle dieser Maßnahmen verschlechterten das Ergebnis mit der DenseNet-Familie und wurden daher verworfen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Daten Augmentation\n","#data_augmentation = tf.keras.Sequential([\n","    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n","    #tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n","    #tf.keras.layers.RandomFlip(mode = 'horizontal'),\n","    #tf.keras.layers.RandomContrast(0.4)\n","#])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Modelkonstruktion\n","Bei der Konstruktion des Gesamtmodells wurden folgende Konzepte getestet:\n","1. Das vom vorigen Abschnitt erwähnte und verworfene Data-Augmentation-layer\n","2. mehrere Denselayer am Ausgang des Modells, um zu testen ob Hinzufügen von Layern einen positiven Effekt hat.\n","    + Dies führte zu einer Verschlechterung\n","3. Ein Denselayer mit mit einer Anzahl der units die der Klassenanzahl entspricht, da das vortrainierte Netz mit 1000 Klassen trainiert wurde.\n","\n","Durch das zuvor erwähnte Einfrieren der Gewichte wird nur die letzte Schicht trainiert."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data Augmentation erweitern\n","model = Sequential([\n","    #data_augmentation,\n","    base_model,\n","    #Dense(256, activation=\"relu\"),\n","    #Dense(128, activation='relu'),\n","    #Dense(64, activation=\"relu\"),\n","    Dense(num_classes, activation='softmax')\n","])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Anpassbare Lernrate\n","Ein wichtiger Parameter um das Ergebnis zu verbessern ist die Lernrate. Eine statische Lernrate sorgt nach einigen Epochen jedoch zu einer Verschlechterung. Eine dynamische Anpassung ist nötig. \n","Hierfür beginnt man mit einer hohen Lernrate, hier wurde der Standard verwendet, und lässt eine  Metrik des Netzes beobachten, hier val_loss. Ändert sich der beobachtete Wert kaum noch über eine bestimmte Anzahl Epochen, wird die Lernrate langsam mit einem Faktor von 0.2 bis auf 1e-6 reduziert.\n","\n","Diese Methode führte zur massiven Verbesserung des Ergebnises.\n","\n","## Optimizer\n","Als Optimizer wurden Adam und SGD getestet. Während Adam schnell zu Verbesserung führte und bereits nach wenigen Epochen zu einer hohen Genauigkeit führte, lieferte SGD selbst nach 25 Epochen kein brauchbares Ergebnis. \n","\n","Somit wurde Adam als geeigneter für das verwendete Densenet169 gewählt."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n","                              patience=2, min_lr=1e-6)\n","optimizer = Adam(learning_rate=1e-4)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Vorzeitiger Stop\n","Wenn das Model über mehrere Epochen keine Verbesserung erzielt, macht ein vorzeitiges Abbrechen Sinn.\n","\n","Die beobachtete Größe um die Verbesserung abzuschätzen ist der val_loss gleich wie bei der Lernratenreduzierung. Da der Value Loss minimiert werden soll ist der Modus 'min'. \n","Die Anzahl Epochen ohne merkliche Veränderung bis zum Stop wurde 10 gewählt. Dies ist nicht auf ein Minimum optimiert worden, da die Gewichte der Epoche mit der besten Metrik übernommen werden."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EarlyStopping_Cb = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 10, restore_best_weights = True, verbose = 1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Modellkompilierung\n","\n","Zur Modellkompilierung kann erwähnt werden, dass die Wahl der Metriken das Ergebnis verbessern kann.\n","\n","So wurde hier das Ergebnis verbessert durch indem neben der Accuracy auch der Mean-Squared Error evaluiert wurde.\n","\n","## Modelltraining\n","\n","Das Modell wurde in 25 Epochen trainiert. Da hier bereits das Modell in weniger Epochen bereits gestoppt wird ist die genaue Anzahl nicht wichtig im Sinne der Optimierung."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T19:19:33.143653Z","iopub.status.busy":"2023-06-25T19:19:33.143272Z","iopub.status.idle":"2023-06-25T21:14:35.698567Z","shell.execute_reply":"2023-06-25T21:14:35.697456Z","shell.execute_reply.started":"2023-06-25T19:19:33.143624Z"},"id":"j85BDjzQNijo","outputId":"59898274-d9bf-473b-f8c8-06472aa72d60","trusted":true},"outputs":[],"source":["model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy', 'mse'])\n","\n","# Trainingsparameter anpassen\n","batch_size = 32\n","epochs = 25\n","# Modelltraining mit erweitertem Data Augmentation\n","model.fit(train_ds,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=val_ds,\n","          callbacks=[reduce_lr, EarlyStopping_Cb])"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction und speichern der Ergebnisse\n","Für die Prediction wurde zunächst eine Liste aller Bildnamen erstellt. Im Anschluss wurde Iterativ alle Bilder durchgegangen und in das Netz gegeben für eine Klassen-Prediction und diese in eine weitere Liste gegeben.\n"," Mit diesen beiden Listen wurde ein Dataframe gebildet dieser in eine CSV-Datei gespeichert.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T21:14:45.153676Z","iopub.status.busy":"2023-06-25T21:14:45.152988Z","iopub.status.idle":"2023-06-25T21:16:52.044476Z","shell.execute_reply":"2023-06-25T21:16:52.043553Z","shell.execute_reply.started":"2023-06-25T21:14:45.153636Z"},"id":"OGw5vbNXJbCp","outputId":"6a550fed-f3ac-4c4a-edc6-412566b05465","trusted":true},"outputs":[],"source":["# Liste für Bildnamen und Vorhersagen\n","image_names = os.listdir('./test_data')\n","class_names = sorted(os.listdir(train_directory))\n","label_predictions = []\n","img_array = []\n","test_directory = 'test_data'\n","\n","\n","# Durchlaufe das Testverzeichnis und lade die Bilder\n","for image_name in image_names:\n","    url = \"./test_data/\" + image_name\n","    img = tf.keras.utils.load_img(url, target_size=image_size)\n","    img_array = tf.keras.utils.img_to_array(img)\n","    img_array = tf.expand_dims(img_array, 0)\n","    predictions = model.predict(img_array)\n","    score = tf.nn.softmax(predictions[0])\n","    label_predictions.append(class_names[np.argmax(score)])\n","\n","\n","# Erstelle den DataFrame und speichere die Vorhersagen in einer CSV-Datei\n","df = pd.DataFrame(columns=['image_id', 'label'])\n","df['image_id'] = image_names\n","df['label'] = label_predictions\n","df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Ergebnisanalyse\n","Folgende Erkenntnisse konnten bei den Versuchen gewonnen werden:\n","+ Verbesserungsansätzte müssen für jedes Netz seperat getestet werden. So zeigte sich eine Verbesserung des Ergebnisses mittels Dataaugmentation beim EfficientNetV2B0. Bei der DenseNet-Familie verschlechterten sich jedoch die Ergebnisse.\n","+ Eine Anpassung der Lernrate erzielte bei jedem getesteten Netz, eine beträchtliche Verbesserung.\n","+ Mit vortrainierten Netzen können sehr schnell gute Ergebnisse erzielt werden.\n","\n","\n","\n","Folgende Aspekte können an diesem Ansatz verbessert werden:\n","+ Zusätzlich zur Produkterkennung eine Texterkennung implementieren und die Ansätze fusionieren\n","+ Bildvorverarbeitungtechniken testen z.b Kontrast aller Bilder erhöhen\n","+ Parameter anpassen die bisher noch nicht angepasst wurden. Beispielsweise wurden die Lerrnraten beim Optimizer und der Lernratenreduzierung beim Versuch mit dem Densenet169 nicht angepasst sondern mit Werten aus Test mit anderen Netzten übernommen.\n","+ Zusätztliche Ansätze zur Optimierung könnten recherchiert werden und getestet werden."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
