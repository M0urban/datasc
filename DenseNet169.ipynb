{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-22T10:36:28.048450Z","iopub.status.busy":"2023-06-22T10:36:28.048040Z","iopub.status.idle":"2023-06-22T10:36:28.057941Z","shell.execute_reply":"2023-06-22T10:36:28.056716Z","shell.execute_reply.started":"2023-06-22T10:36:28.048419Z"},"id":"dWSiczBK8CoZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wget","metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:28.065262Z","iopub.status.busy":"2023-06-22T10:36:28.063452Z","iopub.status.idle":"2023-06-22T10:36:45.460522Z","shell.execute_reply":"2023-06-22T10:36:45.459324Z","shell.execute_reply.started":"2023-06-22T10:36:28.065210Z"},"id":"OqyxUIDU8Coe","outputId":"53645392-5d9d-40d6-d0f8-b848559c70ed","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport random\nimport zipfile","metadata":{"execution":{"iopub.execute_input":"2023-06-25T14:35:27.348339Z","iopub.status.busy":"2023-06-25T14:35:27.347953Z","iopub.status.idle":"2023-06-25T14:35:27.355861Z","shell.execute_reply":"2023-06-25T14:35:27.354632Z","shell.execute_reply.started":"2023-06-25T14:35:27.348311Z"},"id":"WVfs2foH8Cof","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wget https://filr.hs-offenburg.de/filr/public-link/file-download/0dcf8b85882ae199018870bceddf437c/5426/-2254907074900866378/test_data.zip","metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:45.472697Z","iopub.status.busy":"2023-06-22T10:36:45.472338Z","iopub.status.idle":"2023-06-22T10:36:49.980694Z","shell.execute_reply":"2023-06-22T10:36:49.979533Z","shell.execute_reply.started":"2023-06-22T10:36:45.472660Z"},"id":"yBVgiZX38Cog","outputId":"5a2203f8-ea2a-4fa8-fa0c-99e86f83eba0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wget https://zenodo.org/record/7869954/files/products_leaflets_256.zip?download=1","metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:36:49.984006Z","iopub.status.busy":"2023-06-22T10:36:49.983251Z","iopub.status.idle":"2023-06-22T10:44:04.290872Z","shell.execute_reply":"2023-06-22T10:44:04.289628Z","shell.execute_reply.started":"2023-06-22T10:36:49.983967Z"},"id":"Ze6dIoM58Coh","outputId":"4eb3903b-ac94-449b-ab0e-e2172660631d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_zip_file = 'products_leaflets_256.zip'\ndirectory_to_extract_to = '.'\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)","metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:44:04.295623Z","iopub.status.busy":"2023-06-22T10:44:04.294953Z","iopub.status.idle":"2023-06-22T10:44:23.880495Z","shell.execute_reply":"2023-06-22T10:44:23.879418Z","shell.execute_reply.started":"2023-06-22T10:44:04.295590Z"},"id":"JiZS91qB8Coh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UJQFpEiJ8Coi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_zip_file = 'test_data.zip'\ndirectory_to_extract_to = '.'\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)","metadata":{"execution":{"iopub.execute_input":"2023-06-22T10:44:23.882542Z","iopub.status.busy":"2023-06-22T10:44:23.882049Z","iopub.status.idle":"2023-06-22T10:44:24.338457Z","shell.execute_reply":"2023-06-22T10:44:24.337199Z","shell.execute_reply.started":"2023-06-22T10:44:23.882505Z"},"id":"Ufo6N7-F8Coi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"y3vULfpl8Coi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.preprocessing import image\n\n\n# Verzeichnis mit den Trainingsdaten\ntrain_directory = 'products_leaflets_256/train'\nval_directory = 'products_leaflets_256/test'\n\n# Bildgröße und Anzahl der Klassen\nimage_size = (256, 256)\nnum_classes = len(os.listdir(train_directory))\n\n# Daten Augmentation\n#data_augmentation = tf.keras.Sequential([\n    #tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    #tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n    #tf.keras.layers.RandomFlip(mode = 'horizontal')\n#])\n\n# Durchlaufe das Trainingsverzeichnis und lade die Bilder\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    train_directory,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=image_size,\n    shuffle=True,\n    seed=None,\n    validation_split=None,\n    subset=None,\n    interpolation=\"bilinear\",\n    follow_links=False,\n    crop_to_aspect_ratio=False,)\n\n# Durchlaufe das Validierungsverzeichnis und lade die Bilder\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    val_directory,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=image_size,\n    shuffle=True,\n    seed=None,\n    validation_split=None,\n    subset=None,\n    interpolation=\"bilinear\",\n    follow_links=False,\n    crop_to_aspect_ratio=False,)\n\n\n\n\n","metadata":{"execution":{"iopub.execute_input":"2023-06-25T14:35:37.951419Z","iopub.status.busy":"2023-06-25T14:35:37.951056Z","iopub.status.idle":"2023-06-25T14:35:41.944401Z","shell.execute_reply":"2023-06-25T14:35:41.943462Z","shell.execute_reply.started":"2023-06-25T14:35:37.951389Z"},"id":"cf0wCgWd9beC","outputId":"b1303038-2c89-4638-ab46-b7c57e8df9b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, DenseNet121, DenseNet201, DenseNet169\nimport tensorflow.keras.optimizers.legacy as legacy_optimizers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n# Modellarchitektur anpassen\nSTEPS_PER_EPOCH_TRAINING = 10\nSTEPS_PER_EPOCH_VALIDATION = 10\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n#base_model = MobileNetV2(include_top=False, input_shape=(256, 256, 3))\n#base_model = DenseNet121(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\nbase_model = DenseNet169(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n#base_model = DenseNet201(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n#base_model = ResNet50(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n\n#base_model.trainable = false  # Basismodell trainierbar machen\n# Data Augmentation erweitern\nmodel = Sequential([\n    #data_augmentation,\n    base_model,\n    #Dense(256, activation=\"relu\"),\n    #Dense(128, activation='relu'),\n    #Dense(64, activation=\"relu\"),\n    Dense(num_classes, activation='softmax')\n])\nbase_model.layers[0].trainable = False\n# Kompilieren des Modells mit angepasster Lernrate\n\n\n#sgd = legacy_optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=1e-6)\noptimizer = Adam(learning_rate=1e-4)\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Trainingsparameter anpassen\nbatch_size = 32\nepochs = 16\n#early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n# Modelltraining mit erweitertem Data Augmentation\nmodel.fit(train_ds,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=val_ds,\n          callbacks=[reduce_lr])\n\n","metadata":{"execution":{"iopub.execute_input":"2023-06-25T19:19:33.143653Z","iopub.status.busy":"2023-06-25T19:19:33.143272Z","iopub.status.idle":"2023-06-25T21:14:35.698567Z","shell.execute_reply":"2023-06-25T21:14:35.697456Z","shell.execute_reply.started":"2023-06-25T19:19:33.143624Z"},"id":"j85BDjzQNijo","outputId":"59898274-d9bf-473b-f8c8-06472aa72d60","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Liste für Bildnamen und Vorhersagen\nimage_names = os.listdir('./test_data')\nclass_names = sorted(os.listdir(train_directory))\nlabel_predictions = []\nimg_array = []\ntest_directory = 'test_data'\n\n\n# Durchlaufe das Testverzeichnis und lade die Bilder\nfor image_name in image_names:\n    url = \"./test_data/\" + image_name\n    img = tf.keras.utils.load_img(url, target_size=image_size)\n    img_array = tf.keras.utils.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)\n    predictions = model.predict(img_array)\n    score = tf.nn.softmax(predictions[0])\n    label_predictions.append(class_names[np.argmax(score)])\n\n\n# Erstelle den DataFrame und speichere die Vorhersagen in einer CSV-Datei\ndf = pd.DataFrame(columns=['image_id', 'label'])\ndf['image_id'] = image_names\ndf['label'] = label_predictions\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2023-06-25T21:14:45.153676Z","iopub.status.busy":"2023-06-25T21:14:45.152988Z","iopub.status.idle":"2023-06-25T21:16:52.044476Z","shell.execute_reply":"2023-06-25T21:16:52.043553Z","shell.execute_reply.started":"2023-06-25T21:14:45.153636Z"},"id":"OGw5vbNXJbCp","outputId":"6a550fed-f3ac-4c4a-edc6-412566b05465","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"PQ4yzgTvSz5n"}},{"cell_type":"markdown","source":"","metadata":{"id":"m26E3j6USz5o"}},{"cell_type":"markdown","source":"# Neuer Abschnitt","metadata":{"id":"2f2q0TcFJyxb"}},{"cell_type":"code","source":"","metadata":{"id":"cg2aNC1xJDdB"},"execution_count":null,"outputs":[]}]}