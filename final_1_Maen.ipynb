{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFJneqPQCEKb"
      },
      "source": [
        "#### Teamname:\n",
        "#### Score: 0.87571 Kagglename: M_Urban\n",
        "\n",
        "#### Namen der Teammitglieder: Marius Urban, Ramon Jäckle, Maen Hanna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltdTxMOcCEKe"
      },
      "source": [
        "Standardcode aus Beispiel um Daten zu erhalten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-06-22T10:36:28.048450Z",
          "iopub.status.busy": "2023-06-22T10:36:28.048040Z",
          "iopub.status.idle": "2023-06-22T10:36:28.057941Z",
          "shell.execute_reply": "2023-06-22T10:36:28.056716Z",
          "shell.execute_reply.started": "2023-06-22T10:36:28.048419Z"
        },
        "id": "dWSiczBK8CoZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T10:36:28.065262Z",
          "iopub.status.busy": "2023-06-22T10:36:28.063452Z",
          "iopub.status.idle": "2023-06-22T10:36:45.460522Z",
          "shell.execute_reply": "2023-06-22T10:36:45.459324Z",
          "shell.execute_reply.started": "2023-06-22T10:36:28.065210Z"
        },
        "id": "OqyxUIDU8Coe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-25T14:35:27.348339Z",
          "iopub.status.busy": "2023-06-25T14:35:27.347953Z",
          "iopub.status.idle": "2023-06-25T14:35:27.355861Z",
          "shell.execute_reply": "2023-06-25T14:35:27.354632Z",
          "shell.execute_reply.started": "2023-06-25T14:35:27.348311Z"
        },
        "id": "WVfs2foH8Cof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T10:36:45.472697Z",
          "iopub.status.busy": "2023-06-22T10:36:45.472338Z",
          "iopub.status.idle": "2023-06-22T10:36:49.980694Z",
          "shell.execute_reply": "2023-06-22T10:36:49.979533Z",
          "shell.execute_reply.started": "2023-06-22T10:36:45.472660Z"
        },
        "id": "yBVgiZX38Cog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!python -m wget https://filr.hs-offenburg.de/filr/public-link/file-download/0dcf8b85882ae199018870bceddf437c/5426/-2254907074900866378/test_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T10:36:49.984006Z",
          "iopub.status.busy": "2023-06-22T10:36:49.983251Z",
          "iopub.status.idle": "2023-06-22T10:44:04.290872Z",
          "shell.execute_reply": "2023-06-22T10:44:04.289628Z",
          "shell.execute_reply.started": "2023-06-22T10:36:49.983967Z"
        },
        "id": "Ze6dIoM58Coh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!python -m wget https://zenodo.org/record/7869954/files/products_leaflets_256.zip?download=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T10:44:04.295623Z",
          "iopub.status.busy": "2023-06-22T10:44:04.294953Z",
          "iopub.status.idle": "2023-06-22T10:44:23.880495Z",
          "shell.execute_reply": "2023-06-22T10:44:23.879418Z",
          "shell.execute_reply.started": "2023-06-22T10:44:04.295590Z"
        },
        "id": "JiZS91qB8Coh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_to_zip_file = 'products_leaflets_256.zip'\n",
        "directory_to_extract_to = '.'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJQFpEiJ8Coi",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T10:44:23.882542Z",
          "iopub.status.busy": "2023-06-22T10:44:23.882049Z",
          "iopub.status.idle": "2023-06-22T10:44:24.338457Z",
          "shell.execute_reply": "2023-06-22T10:44:24.337199Z",
          "shell.execute_reply.started": "2023-06-22T10:44:23.882505Z"
        },
        "id": "Ufo6N7-F8Coi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_to_zip_file = 'test_data.zip'\n",
        "directory_to_extract_to = '.'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CuHzHzyCEKm"
      },
      "source": [
        "## Bildgröße und Datenverzeichnisse\n",
        "\n",
        "1. Zuerst werden die Verzeichnisse für die Trainings- und Validierungsdaten festgelegt. Das Verzeichnis **train_directory** enthält die Bilder, die für das Training verwendet werden, und das Verzeichnis **val_directory** enthält die Bilder für die Validierung.\n",
        "\n",
        "2. Die Bildgröße (**image_size**) wird auf (**256, 256**) festgelegt, was die Größe ist, auf die alle Bilder während des Trainings und der Validierung skaliert werden. Für Bilder muss eine konstante Größe gewählt werden, da dies von den Netzwerken erwartet werden, aber die Bilder aus den Prospekten nicht immer gleich groß sind. **Anmerkung: evtl. Warum größe gewählt**\n",
        "\n",
        "3. Die Anzahl der Klassen (**num_classes**) wird automatisch festgelegt, indem die Anzahl der Unterordner (**Klassen**) im Trainingsverzeichnis gezählt wird. Jeder Unterordner im Trainingsverzeichnis repräsentiert eine Klasse von Produkten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3vULfpl8Coi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Verzeichnis mit den Trainingsdaten\n",
        "train_directory = 'products_leaflets_256/train'\n",
        "val_directory = 'products_leaflets_256/test'\n",
        "\n",
        "# Bildgröße und Anzahl der Klassen\n",
        "#\n",
        "image_size = (256, 256)\n",
        "num_classes = len(os.listdir(train_directory))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbo0xQkoCEKo"
      },
      "source": [
        "## Laden der Bilder\n",
        "Es würde die Funktion **tf.keras.utils.image_dataset_from_directory** von TensorFlow/Keras, um Trainings- und Validierungsdatasets aus den entsprechenden Verzeichnissen zu erstellen, verwendet.\n",
        "Diese Funktion bietet viele möglichkeiten um die daten zu laden und verarbeiten.\n",
        "Für das Trainings- und Validierungsdaten wird die Funktion aufgerufen und mit den entsprechenden Parametern konfiguriert. Das Datenverzeichnis wird angegeben, sowie einige Einstellungen für die Datenverarbeitung:\n",
        "\n",
        "  * **labels=\"inferred\"**: Die Zielvariablen (Labels) werden automatisch aus den    Verzeichnisnamen abgeleitet. Jeder Unterordner im Trainingsverzeichnis repräsentiert eine Klasse.\n",
        "  * **label_mode=\"int\"**: Die Zielvariablen werden als Integer (ganzzahlige Werte) dargestellt, da sie nicht One-Hot-kodiert sind.\n",
        "  * **color_mode=\"rgb\"**: Die Bilder werden im RGB-Farbraum geladen, was üblicherweise bei den meisten Bilderkennungs-Aufgaben der Fall ist.\n",
        "  * **batch_size=32**: Die Bilder werden in Batches mit einer Größe von 32 geladen, um den Speicher effizient zu nutzen.\n",
        "  * **image_size=image_size**: Die Bilder werden auf die vorher festgelegte Bildgröße (256, 256) skaliert, um eine einheitliche Größe für das Modelltraining zu gewährleisten.\n",
        "  * **shuffle=True**: Die Bilder werden vor dem Training zufällig durchmischt, um die Daten während des Trainings besser zu mischen und ein besseres Training zu ermöglichen. **Anmerkung: vlt noch beschreiben was am TRaining besser wird.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-25T14:35:37.951419Z",
          "iopub.status.busy": "2023-06-25T14:35:37.951056Z",
          "iopub.status.idle": "2023-06-25T14:35:41.944401Z",
          "shell.execute_reply": "2023-06-25T14:35:41.943462Z",
          "shell.execute_reply.started": "2023-06-25T14:35:37.951389Z"
        },
        "id": "cf0wCgWd9beC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Durchlaufe das Trainingsverzeichnis und lade die Bilder\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=image_size,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,)\n",
        "\n",
        "# Durchlaufe das Validierungsverzeichnis und lade die Bilder\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=image_size,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H-MJDfnPoO1"
      },
      "source": [
        "### Funktionen Impotieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO40xBAyCEKp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "import tensorflow.keras.optimizers.legacy as legacy_optimizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70eDK08bCEKq"
      },
      "source": [
        "## Netzauswahl\n",
        "\n",
        "EfficientNetB0, EfficientNetB0, ResNet50, ResNet100, MobileNetV2, selbstgebautes Alexnet, DenseNet121, DenseNet169, DenseNet201.\n",
        "**Anmerkung sollen Netze zwei mal aufgelistet werden?**\n",
        "Es wurden verschiedene von Keras bereitgestellte Bilderkennungsnetze wie (EfficientNetV2B0, EfficientNetV2B0, ResNet50, ResNet101, MobileNetV2, selbstgebautes Alexnet, DenseNet121, DenseNet169, DenseNet201) getestet.\n",
        "\n",
        "DenseNet169 schnitt am besten ab und wurde deshalb gewählt. Außerdem wurde diese ansatz verwendet, da bei DensNet169 dichte Verbindung von Schichten ermöglicht eine bessere Nutzung von Merkmalen aus früheren Schichten. Desweiteren kann DensNet169 komplexere Merkmale in tieferen Schichten lernen.\n",
        "\n",
        "**Beschreibung der Lösung:** **Anmerkung: Nicht in Wir Form neutraler Stil**\n",
        "  1. Wir laden das vortrainierte Modell DenseNet169 ohne die Ausgangsschicht mit **include_top=False** und **weights='imagenet'**. Damit erhalten wir das Modell ohne die Klassifikationsschicht. Wir können es dann an unser Problem anpassen.\n",
        "  2. Durch Setzen von **layer.trainable = False** für jede Schicht frieren wir alle Schichten des Basismodells ein. Das bedeutet, dass die Basismodell-Gewichte nicht aktualisiert werden und wir uns darauf konzentrieren können, die neuen Ausgangsschichten zu trainieren.\n",
        "  3. Wir fügen neue Ausgangsschichten hinzu, um das Modell für unsere spezifische Aufgabe anzupassen. In unserem Fall fügen wir eine finale Dense-Schicht mit der Anzahl der Klassen hinzu.\n",
        "  4. Das Modell wird mit einer niedrigen Lernrate von 1e-4 kompiliert, um das Risiko von starken Änderungen der vortrainierten Gewichte zu verringern. Außerdem wird während der laufzeit durch die funktion **ReduceLROnPlateau** die Lernrate reduziert, um bessere ergebnisse zu erzielen.**Anmerkung: Begründung komisch in 3 saGST DU du hast die vortrainierten layer nicht trainierbar gemacht, hier sagts du die vortrainierten Gewichte sollen nicht durch eine zu große Lernrate verändert werden**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxSCMShuCEKq"
      },
      "outputs": [],
      "source": [
        "# Modellarchitektur anpassen\n",
        "\n",
        "#base_model = MobileNetV2(include_top=False, input_shape=(256, 256, 3))\n",
        "#base_model = DenseNet121(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n",
        "base_model = DenseNet169(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n",
        "#base_model = DenseNet201(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))\n",
        "#base_model = ResNet50(include_top=False, pooling='avg', weights = 'imagenet', input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ppBKHSbCEKr"
      },
      "source": [
        "## Data Augmentation\n",
        "Bei der Datenagumentation werden verschiedene Transformationen auf die vorhandenen Trainingsdaten angewendet. Dadurch werden neue, leicht veränderte Versionen der Bilder erzeugt, die jedoch dieselben Merkmale und Klassen enthalten. Diese künstlich erzeugten Daten können dem Modell dabei helfen, eine bessere Generalisierungsfähigkeit zu entwickeln, indem sie es in die Lage versetzen, Variationen von Bildern besser zu erkennen und zu verarbeiten.\n",
        "Es wurden folgende Augmentations getestet:\n",
        "\n",
        "1. Zufällige Rotation des Bildes\n",
        "2. Zufälliges Heran-Zoomen\n",
        "3. Zufälliges horizontales spiegeln\n",
        "4. Zufällige Kontraständerungen\n",
        "\n",
        "Ausnahmslos alle dieser Masnahmen verschlechterten das Ergebnis in DensNet169 und wurden daher verworfen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l65-kNN2CEKr"
      },
      "outputs": [],
      "source": [
        "# Daten Augmentation\n",
        "#data_augmentation = tf.keras.Sequential([\n",
        "    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    #tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    #tf.keras.layers.RandomFlip(mode = 'horizontal'),\n",
        "    #tf.keras.layers.RandomContrast(0.4)\n",
        "#])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT8bjNo1CEKs"
      },
      "source": [
        "## Modelkonstruktion\n",
        "Bei der Konstruktion des Gesamtmodells wurden folgende Dinge getestet:\n",
        "1. Wie bereits weiter oben erläutert, handelt es sich bei der **data_augmentation** um eine Sequenz von Transformationen, die auf die Bilder des Trainingsdatensatzes angewendet werden, um neue, leicht veränderte Versionen der Bilder zu erzeugen. Diese Layer wurde verwurfen, da bei unsere Ansatz das nicht gebracht hat.\n",
        "2. Mehrere **Dense_Layer** mit einer unterschiedlichen Anzahl von Neuronen. Dies führte zu einem schlechteren Ergebnis. Daher wurden diese Layer verworfen. **Anmerkung:warum diese Layer probiert?**\n",
        "3. Die finale **Dense_layer**, die die Ausgabe des Modells darstellt. Die Anzahl der Neuronen entspricht der Anzahl der Klassen im Datensatz, und die Softmax-Aktivierungsfunktion wird verwendet, um eine Wahrscheinlichkeitsverteilung über die verschiedenen Klassen zu berechnen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akmSAkM1CEKs"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation erweitern\n",
        "model = Sequential([\n",
        "    #data_augmentation,\n",
        "    base_model,\n",
        "    #Dense(256, activation=\"relu\"),\n",
        "    #Dense(128, activation='relu'),\n",
        "    #Dense(64, activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "base_model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCWvR8ENCEKs"
      },
      "source": [
        "## Anpassbare Lernrate\n",
        "**ReduceLROnPlateau**: ist ein Callback in Keras, der automatisch die Lernrate des Optimierers anpasst, wenn ein bestimmtes Plateau erreicht wird, um die Validierungsverlustfunktion (val_loss) zu verbessern. Das heißt, wenn sich die Modellleistung auf dem Validierungsdatensatz nicht weiter verbessert, wird die Lernrate reduziert(factor = 0.2), um zu versuchen, in kleineren Schritten zu lernen.\n",
        "\n",
        "Diese Methode führte zu masiven Verbesserung des Ergebnis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWvTqBsQCEKt"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66E98RSEKWz4"
      },
      "source": [
        "## Optimimizer\n",
        "Es wurden 2 ansätze gestestet:\n",
        "  + **Adam**: ist ein häufig verwendeter Optimierungsalgorithmus für das Training von neuronalen Netzwerken. Diese erzielte bei der DenseNet169 ein sehr gutes ergebniss.\n",
        "  + **legacy_optimizer SGD**: Diese Optimierungsalgorithmus wuerde auf das DensNet169 verwendet, aber führte zu schlechtere Ergebnisse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiopCQ3qKUyD"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC8a8oT_KUbr"
      },
      "outputs": [],
      "source": [
        "#sgd = legacy_optimizers.SGD(lr = 0.01, momentum = 0.9, nesterov = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtQwwWRvCEKt"
      },
      "source": [
        "## Vorzeitiges Stoppen\n",
        "\n",
        "Early Stopping hilft dabei, zu verhindern, dass das Modell Rauschen in den Trainingsdaten auswendig lernt, und fördert das Lernen allgemeiner Muster. Es kann auch Rechenressourcen und Zeit sparen, da das Training gestoppt wird, sobald das Modell ein geeignetes Leistungsniveau erreicht hat, anstatt für die maximale Anzahl von Trainingsepochen ausgeführt zu werden.Es ist nützlich, um das Übertraining (Overfitting) zu verhindern und die besten Modellgewichte zu speichern.\n",
        "\n",
        "Auswahl der Parameter:\n",
        "\n",
        "\n",
        "1.   **monitor='val_loss'**: Die Metrik, die überwacht wird, um zu entscheiden, wann das Training gestoppt werden soll.\n",
        "2.   **mode='min'**: Die Art der Überwachung. In diesem Fall wird nach einer Minimierung des Validierungsverlustes gesucht.\n",
        "3. **patience=10**: Die Anzahl der Epochen, die gewartet werden sollen, wenn keine Verbesserung des Validierungsverlustes festgestellt wird.\n",
        "4. **restore_best_weights=True**: Wenn True, wird das Modell nach dem Training auf die Gewichte zurückgesetzt, die den niedrigsten Validierungsverlust erzielt haben.\n",
        "5. **verbose=1**: Das Level der Ausgaben während des Trainings. Wenn 1, werden Informationen über das Training und die Beendigung des Trainings angezeigt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZl6UNaICEKu"
      },
      "outputs": [],
      "source": [
        "EarlyStopping_Cb = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 10, restore_best_weights = True, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjReK9YgCEKu"
      },
      "source": [
        "## Modelkompilierung\n",
        "\n",
        "Zur Modelkompilierung kann erwähnt werden, dass die Wahl der Metriken das Ergebnis verbessern kann.\n",
        "So wurde hier das Ergebnis verbessert durch indem neben der Accuracy auch der Mean-Squared Error evaluiert wurde.\n",
        "\n",
        "## Modeltraining\n",
        "\n",
        "Das Model wurde in 25 Epochen trainiert, da hier bereits das Model innerhalb dieser garantiert durch den vorzeitigen Stop beendet wurde.\n",
        "Es wurde eine batch_size von 32 gewählt, da damit bisher die besten Ergebnisse erzielt wurden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-25T19:19:33.143653Z",
          "iopub.status.busy": "2023-06-25T19:19:33.143272Z",
          "iopub.status.idle": "2023-06-25T21:14:35.698567Z",
          "shell.execute_reply": "2023-06-25T21:14:35.697456Z",
          "shell.execute_reply.started": "2023-06-25T19:19:33.143624Z"
        },
        "id": "j85BDjzQNijo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy', 'mse'])\n",
        "\n",
        "# Trainingsparameter anpassen\n",
        "batch_size = 32\n",
        "epochs = 25\n",
        "# Modelltraining mit erweitertem Data Augmentation\n",
        "model.fit(train_ds,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=val_ds,\n",
        "          callbacks=[reduce_lr, EarlyStopping_Cb])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpXSF8GSX5op"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0kNK40HCEKv"
      },
      "source": [
        "## Prediction und speichern der Ergebnisse\n",
        "Das Testverzeichnis wird durchlaufen, und für jedes Testbild wird eine Vorhersage mit dem Modell durchgeführt. Die Vorhersagen werden in einer Liste **label_predictions** gespeichert, wobei jedem Testbild der entsprechende Klassenname zugeordnet wird.\n",
        "\n",
        "Anschließend wird ein leeres Pandas DataFrame df erstellt, das zwei Spalten enthält: \"**image_id**\" für die Dateinamen der Testbilder und \"**label**\" für die Vorhersagen.\n",
        "\n",
        "Die Liste der Dateinamen der Testbilder (**image_names**) und die Liste der Vorhersagen (**label_predictions**) werden dem DataFrame zugewiesen.\n",
        "\n",
        "Schließlich wird das DataFrame in eine CSV-Datei mit dem Namen \"**submission.csv**\" gespeichert.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-25T21:14:45.153676Z",
          "iopub.status.busy": "2023-06-25T21:14:45.152988Z",
          "iopub.status.idle": "2023-06-25T21:16:52.044476Z",
          "shell.execute_reply": "2023-06-25T21:16:52.043553Z",
          "shell.execute_reply.started": "2023-06-25T21:14:45.153636Z"
        },
        "id": "OGw5vbNXJbCp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Liste für Bildnamen und Vorhersagen\n",
        "image_names = os.listdir('./test_data')\n",
        "class_names = sorted(os.listdir(train_directory))\n",
        "label_predictions = []\n",
        "img_array = []\n",
        "test_directory = 'test_data'\n",
        "\n",
        "\n",
        "# Durchlaufe das Testverzeichnis und lade die Bilder\n",
        "for image_name in image_names:\n",
        "    url = \"./test_data/\" + image_name\n",
        "    img = tf.keras.utils.load_img(url, target_size=image_size)\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    predictions = model.predict(img_array)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "    label_predictions.append(class_names[np.argmax(score)])\n",
        "\n",
        "\n",
        "# Erstelle den DataFrame und speichere die Vorhersagen in einer CSV-Datei\n",
        "df = pd.DataFrame(columns=['image_id', 'label'])\n",
        "df['image_id'] = image_names\n",
        "df['label'] = label_predictions\n",
        "df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ4yzgTvSz5n"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f2q0TcFJyxb"
      },
      "source": [
        "## Ergebnisanalyse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg2aNC1xJDdB"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
