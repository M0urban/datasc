{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-06-09T20:46:55.348320Z",
          "iopub.execute_input": "2023-06-09T20:46:55.348770Z",
          "iopub.status.idle": "2023-06-09T20:46:55.359327Z",
          "shell.execute_reply.started": "2023-06-09T20:46:55.348734Z",
          "shell.execute_reply": "2023-06-09T20:46:55.357808Z"
        },
        "trusted": true,
        "id": "dWSiczBK8CoZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:46:55.361943Z",
          "iopub.execute_input": "2023-06-09T20:46:55.362391Z",
          "iopub.status.idle": "2023-06-09T20:47:08.512557Z",
          "shell.execute_reply.started": "2023-06-09T20:46:55.362334Z",
          "shell.execute_reply": "2023-06-09T20:47:08.510642Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqyxUIDU8Coe",
        "outputId": "a40d2939-78a9-47c3-fca7-d528e88942bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=474426c95a793eb2049caffdd488c7e74d1cd762b61d5374d4a174c68709d721\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:47:08.514738Z",
          "iopub.execute_input": "2023-06-09T20:47:08.515175Z",
          "iopub.status.idle": "2023-06-09T20:47:08.522698Z",
          "shell.execute_reply.started": "2023-06-09T20:47:08.515133Z",
          "shell.execute_reply": "2023-06-09T20:47:08.521298Z"
        },
        "trusted": true,
        "id": "WVfs2foH8Cof"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m wget https://filr.hs-offenburg.de/filr/public-link/file-download/0dcf8b85882ae199018870bceddf437c/5426/-2254907074900866378/test_data.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:47:08.525801Z",
          "iopub.execute_input": "2023-06-09T20:47:08.526588Z",
          "iopub.status.idle": "2023-06-09T20:47:14.741613Z",
          "shell.execute_reply.started": "2023-06-09T20:47:08.526545Z",
          "shell.execute_reply": "2023-06-09T20:47:14.739961Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBVgiZX38Cog",
        "outputId": "74607596-910c-40ed-903c-53d7935794d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved under test_data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m wget https://zenodo.org/record/7869954/files/products_leaflets_256.zip?download=1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:47:14.744283Z",
          "iopub.execute_input": "2023-06-09T20:47:14.745882Z",
          "iopub.status.idle": "2023-06-09T20:48:23.407129Z",
          "shell.execute_reply.started": "2023-06-09T20:47:14.745819Z",
          "shell.execute_reply": "2023-06-09T20:48:23.405628Z"
        },
        "trusted": true,
        "id": "Ze6dIoM58Coh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6548df79-294d-4fec-c4cd-f2eaea58ca14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved under products_leaflets_256.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip_file = 'products_leaflets_256.zip'\n",
        "directory_to_extract_to = '.'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:48:23.409082Z",
          "iopub.execute_input": "2023-06-09T20:48:23.409614Z",
          "iopub.status.idle": "2023-06-09T20:48:41.963247Z",
          "shell.execute_reply.started": "2023-06-09T20:48:23.409572Z",
          "shell.execute_reply": "2023-06-09T20:48:41.961818Z"
        },
        "trusted": true,
        "id": "JiZS91qB8Coh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UJQFpEiJ8Coi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip_file = 'test_data.zip'\n",
        "directory_to_extract_to = '.'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:48:41.964771Z",
          "iopub.execute_input": "2023-06-09T20:48:41.965102Z",
          "iopub.status.idle": "2023-06-09T20:48:42.601581Z",
          "shell.execute_reply.started": "2023-06-09T20:48:41.965067Z",
          "shell.execute_reply": "2023-06-09T20:48:42.597942Z"
        },
        "trusted": true,
        "id": "Ufo6N7-F8Coi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T20:49:52.107873Z",
          "iopub.execute_input": "2023-06-09T20:49:52.110265Z",
          "iopub.status.idle": "2023-06-09T20:49:52.200293Z",
          "shell.execute_reply.started": "2023-06-09T20:49:52.110171Z",
          "shell.execute_reply": "2023-06-09T20:49:52.197877Z"
        },
        "trusted": true,
        "id": "y3vULfpl8Coi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# Verzeichnis mit den Trainingsdaten\n",
        "train_directory = 'products_leaflets_256/train'\n",
        "\n",
        "# Bildgröße und Anzahl der Klassen\n",
        "image_size = (224, 224)\n",
        "num_classes = len(os.listdir(train_directory))\n",
        "\n",
        "# Liste für Bilder und Labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Durchlaufe das Trainingsverzeichnis und lade die Bilder\n",
        "for root, dirs, files in os.walk(train_directory):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            image_path = os.path.join(root, file)\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            image = image.resize(image_size)\n",
        "            image_array = np.array(image)\n",
        "            images.append(image_array)\n",
        "            labels.append(int(os.path.basename(root)))\n",
        "\n",
        "# Konvertiere die Listen in Numpy-Arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cf0wCgWd9beC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "#ResNet50 with defaul parameters\n",
        "model = ResNet50()\n",
        "model2 = model.compile()\n",
        "\n",
        "\n",
        "# Trainieren des Modells mit 10 durchläufen\n",
        "model.fit(images, labels, batch_size=32, epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "id": "j85BDjzQNijo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste für Bildnamen und Vorhersagen\n",
        "image_names = []\n",
        "label_predictions = []\n",
        "\n",
        "# Durchlaufe das Testverzeichnis und lade die Bilder\n",
        "for root, dirs, files in os.walk(test_directory):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            image_path = os.path.join(root, file)\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            image = image.resize(image_size)\n",
        "            image_array = np.array(image)\n",
        "            image_names.append(file)\n",
        "            label_prediction = model.predict(np.expand_dims(image_array, axis=0))\n",
        "            label_predictions.append(np.argmax(label_prediction))\n",
        "\n",
        "# Erstelle den DataFrame und speichere die Vorhersagen in einer CSV-Datei\n",
        "df = pd.DataFrame(columns=['image_id', 'label'])\n",
        "df['image_id'] = image_names\n",
        "df['label'] = label_predictions\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "OGw5vbNXJbCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "2f2q0TcFJyxb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cg2aNC1xJDdB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}