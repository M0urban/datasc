{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-09T20:46:55.348770Z","iopub.status.busy":"2023-06-09T20:46:55.348320Z","iopub.status.idle":"2023-06-09T20:46:55.359327Z","shell.execute_reply":"2023-06-09T20:46:55.357808Z","shell.execute_reply.started":"2023-06-09T20:46:55.348734Z"},"id":"dWSiczBK8CoZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wget","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:46:55.362391Z","iopub.status.busy":"2023-06-09T20:46:55.361943Z","iopub.status.idle":"2023-06-09T20:47:08.512557Z","shell.execute_reply":"2023-06-09T20:47:08.510642Z","shell.execute_reply.started":"2023-06-09T20:46:55.362334Z"},"id":"OqyxUIDU8Coe","outputId":"a40d2939-78a9-47c3-fca7-d528e88942bd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport random\nimport zipfile","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:47:08.515175Z","iopub.status.busy":"2023-06-09T20:47:08.514738Z","iopub.status.idle":"2023-06-09T20:47:08.522698Z","shell.execute_reply":"2023-06-09T20:47:08.521298Z","shell.execute_reply.started":"2023-06-09T20:47:08.515133Z"},"id":"WVfs2foH8Cof","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wget https://filr.hs-offenburg.de/filr/public-link/file-download/0dcf8b85882ae199018870bceddf437c/5426/-2254907074900866378/test_data.zip","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:47:08.526588Z","iopub.status.busy":"2023-06-09T20:47:08.525801Z","iopub.status.idle":"2023-06-09T20:47:14.741613Z","shell.execute_reply":"2023-06-09T20:47:14.739961Z","shell.execute_reply.started":"2023-06-09T20:47:08.526545Z"},"id":"yBVgiZX38Cog","outputId":"74607596-910c-40ed-903c-53d7935794d1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wget https://zenodo.org/record/7869954/files/products_leaflets_256.zip?download=1","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:47:14.745882Z","iopub.status.busy":"2023-06-09T20:47:14.744283Z","iopub.status.idle":"2023-06-09T20:48:23.407129Z","shell.execute_reply":"2023-06-09T20:48:23.405628Z","shell.execute_reply.started":"2023-06-09T20:47:14.745819Z"},"id":"Ze6dIoM58Coh","outputId":"6548df79-294d-4fec-c4cd-f2eaea58ca14","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_zip_file = 'products_leaflets_256.zip'\ndirectory_to_extract_to = '.'\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:48:23.409614Z","iopub.status.busy":"2023-06-09T20:48:23.409082Z","iopub.status.idle":"2023-06-09T20:48:41.963247Z","shell.execute_reply":"2023-06-09T20:48:41.961818Z","shell.execute_reply.started":"2023-06-09T20:48:23.409572Z"},"id":"JiZS91qB8Coh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UJQFpEiJ8Coi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_zip_file = 'test_data.zip'\ndirectory_to_extract_to = '.'\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:48:41.965102Z","iopub.status.busy":"2023-06-09T20:48:41.964771Z","iopub.status.idle":"2023-06-09T20:48:42.601581Z","shell.execute_reply":"2023-06-09T20:48:42.597942Z","shell.execute_reply.started":"2023-06-09T20:48:41.965067Z"},"id":"Ufo6N7-F8Coi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2023-06-09T20:49:52.110265Z","iopub.status.busy":"2023-06-09T20:49:52.107873Z","iopub.status.idle":"2023-06-09T20:49:52.200293Z","shell.execute_reply":"2023-06-09T20:49:52.197877Z","shell.execute_reply.started":"2023-06-09T20:49:52.110171Z"},"id":"y3vULfpl8Coi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.utils import image_dataset_from_directory\n\n\n\n# Verzeichnis mit den Trainingsdaten\ntrain_directory = 'products_leaflets_256/train'\n\n# Bildgröße und Anzahl der Klassen\nimage_size = (256, 256)\nnum_classes = len(os.listdir(train_directory))\n\n# Liste für Bilder und Labels\nimages = []\nlabels = []\ntrain_dataset = image_dataset_from_directory(\n    train_directory,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(256, 256),\n    shuffle=True,\n    seed=None,\n    validation_split=None,\n    subset=None,\n    interpolation=\"bilinear\",\n    follow_links=False,\n    crop_to_aspect_ratio=False,\n)\n\n\n\n","metadata":{"id":"cf0wCgWd9beC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.preprocessing import image\n\n\n#Densenet121 with defaul parameters\nmodel = DenseNet121(\n    include_top=True,\n    weights=None,\n    input_tensor=None,\n    input_shape=(256, 256, 3),\n    pooling=None,\n    classes=832,\n    classifier_activation=\"softmax\",\n)\nmodel2 = model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n\n\n# Trainieren des Modells mit 10 durchläufen\nmodel.fit(train_dataset, batch_size=32, epochs=50)","metadata":{"id":"j85BDjzQNijo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Liste für Bildnamen und Vorhersagen\nimage_names = []\nlabel_predictions = []\ntest_directory = 'test_data'\n\nmodel.save_weights('my_model_weights.h5')\n\n# Durchlaufe das Testverzeichnis und lade die Bilder\nfor root, dirs, files in os.walk(test_directory):\n    for file in files:\n        if file.endswith('.jpg'):\n            image_path = os.path.join(root, file)\n            image = Image.open(image_path).convert('RGB')\n            image = image.resize(image_size)\n            image_array = np.array(image)\n            image_names.append(file)\n            label_prediction = model.predict(np.expand_dims(image_array, axis=0))\n            label_predictions.append(np.argmax(label_prediction))\n\n# Erstelle den DataFrame und speichere die Vorhersagen in einer CSV-Datei\ndf = pd.DataFrame(columns=['image_id', 'label'])\ndf['image_id'] = image_names\ndf['label'] = label_predictions\ndf.to_csv('submission.csv', index=False)","metadata":{"id":"OGw5vbNXJbCp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neuer Abschnitt","metadata":{"id":"2f2q0TcFJyxb"}},{"cell_type":"code","source":"","metadata":{"id":"cg2aNC1xJDdB"},"execution_count":null,"outputs":[]}]}